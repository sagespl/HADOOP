<workflow-app xmlns="uri:oozie:workflow:0.4" name="sages-oozie">

    <start to="sqoop"/>

    <action name="sqoop">
        <sqoop xmlns="uri:oozie:sqoop-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <prepare>
                <delete path="${sqoopOutputPath}"/>
            </prepare>
            <configuration>
                <property>
                    <name>mapred.compress.map.output</name>
                    <value>true</value>
                </property>
            </configuration>
            <command>import --connect jdbc:mysql://localhost:3306/sakila --table customer --username sages --password password --driver com.mysql.jdbc.Driver --warehouse-dir /user/sages/sqoop/  --num-mappers 1</command>
        </sqoop>
        <ok to="distcp"/>
        <error to="fail"/>
    </action>

    <action name="distcp">
        <distcp xmlns="uri:oozie:distcp-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <arg>${distcpInputPath}</arg>
            <arg>${distcpOutputPath}</arg>
        </distcp>
        <ok to="wordcount"/>
        <error to="fail"/>
    </action>

    <action name="wordcount">
        <map-reduce>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <prepare>
                <delete path="${nameNode}${wordcountOutputPath}"/>
            </prepare>
            <configuration>

                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>

                <property>
                    <name>mapred.mapper.new-api</name>
                    <value>true</value>
                </property>
                <property>
                    <name>mapred.reducer.new-api</name>
                    <value>true</value>
                </property>

                <property>
                    <name>mapreduce.job.map.class</name>
                    <value>pl.com.sages.hadoop.mapreduce.wordcount.WordCountMapper</value>
                </property>
                <property>
                    <name>mapreduce.job.reduce.class</name>
                    <value>pl.com.sages.hadoop.mapreduce.wordcount.WordCountReducer</value>
                </property>

                <property>
                    <name>mapreduce.job.output.key.class</name>
                    <value>org.apache.hadoop.io.Text</value>
                </property>
                <property>
                    <name>mapreduce.job.output.value.class</name>
                    <value>org.apache.hadoop.io.IntWritable</value>
                </property>

                <property>
                    <name>mapreduce.input.fileinputformat.inputdir</name>
                    <value>${wordcountInputPath}</value>
                </property>
                <property>
                    <name>mapreduce.output.fileoutputformat.outputdir</name>
                    <value>${wordcountOutputPath}</value>
                </property>
            </configuration>
        </map-reduce>
        <ok to="invertedindex"/>
        <error to="fail"/>
    </action>

    <action name="invertedindex">
        <map-reduce>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <prepare>
                <delete path="${nameNode}${invertedindexOutputPath}"/>
            </prepare>
            <configuration>

                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>

                <property>
                    <name>mapred.mapper.new-api</name>
                    <value>true</value>
                </property>
                <property>
                    <name>mapred.reducer.new-api</name>
                    <value>true</value>
                </property>

                <property>
                    <name>mapreduce.job.map.class</name>
                    <value>pl.com.sages.hadoop.mapreduce.invertedindex.InvertedIndexMapper</value>
                </property>
                <property>
                    <name>mapreduce.job.reduce.class</name>
                    <value>pl.com.sages.hadoop.mapreduce.invertedindex.InvertedIndexReducer</value>
                </property>

                <property>
                    <name>mapreduce.job.output.key.class</name>
                    <value>org.apache.hadoop.io.Text</value>
                </property>
                <property>
                    <name>mapreduce.job.output.value.class</name>
                    <value>org.apache.hadoop.io.Text</value>
                </property>

                <property>
                    <name>mapreduce.input.fileinputformat.inputdir</name>
                    <value>${invertedindexInputPath}</value>
                </property>
                <property>
                    <name>mapreduce.output.fileoutputformat.outputdir</name>
                    <value>${invertedindexOutputPath}</value>
                </property>
            </configuration>
        </map-reduce>
        <ok to="end"/>
        <error to="fail"/>
    </action>

    <kill name="fail">
        <message>Map/Reduce failed, error message[${wf:errorMessage(wf:lastErrorNode())}]</message>
    </kill>

    <end name="end"/>

</workflow-app>
